# AI_Webscrapper
An AI web scrapper using OLLama, Llama3.1, and Selenium. Here I have used the Llama3.1 8B variant (a free open-source variant that takes space of about ~4.7GB ) as the main Generative AI model for parsing. The whole extraction process of the data from the website is done by using Selenium along with BeautifulSoup(bs4). The entire project is divided into three parts:

1. The front-end has been made using Streamlit (the most commonly used front-end framework). Download it by writing Pip install streamlit or python install streamlit or Pip3 install streamlit or python3 install streamlit in your terminal.
2. The data was extracted using selenium and beautiful soup. Here I have used chrome driver to access the website URL for reading and extracting. The version that I have used here is https://storage.googleapis.com/chrome-for-testing-public/129.0.6668.89/win64/chromedriver-win64.zip. However you can download the file based on your operating system by using this link https://googlechromelabs.github.io/chrome-for-testing/#stable.
3. For Data parsing, I have used OLLama software, you can download it from here https://ollama.com/. Now from this, I have visited this website https://github.com/ollama/ollama  to pull the generative AI model for llama. I have used Llama3.1 with an 8B parameter. After installing Ollama in your system, run this command ollama to check whether your system has successfully installed Ollama or not, and after that use this command ollama pull llama3.1 or any other version. If you want to test the model in the terminal/command prompt you can use, ollama run llama3.1 and you can ask any question to it.

This project will be very slow in processing as I don't have any GPU support but for some machines, this will take hardly ~5-10 min. Mine took ~15-20 min (it might vary because of using the lower Llama3.1 variant). This is the brief about the project. Don't forget to install the dependencies from the requirement.txt file using this command pip/python install -r requirement.txt or pip3/python3 install -r requirement.txt and always use a virtual environment.  
